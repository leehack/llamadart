name: llamadart
description: A Dart/Flutter plugin for llama.cpp - run LLM inference on any platform using GGUF models
version: 0.2.0
homepage: https://github.com/leehack/llamadart
repository: https://github.com/leehack/llamadart
issue_tracker: https://github.com/leehack/llamadart/issues
topics:
  - llama
  - llm
  - ai
  - inference
  - gguf


environment:
  sdk: '>=3.6.0 <4.0.0'
  flutter: ">=3.10.0"

dependencies:
  ffi: ^2.1.0
  path: ^1.8.3
  meta: ^1.11.0
  http: ^1.1.0
  web: ^1.0.0
  flutter:
    sdk: flutter
  flutter_web_plugins:
    sdk: flutter

dev_dependencies:
  archive: ^4.0.7
  ffigen: ^20.1.1
  hooks: ^1.0.0
  lints: ^6.0.0
  native_assets_cli: ^0.18.0
  test: ^1.29.0

flutter:
  plugin:
    platforms:
      android:
        ffiPlugin: true
      ios:
        ffiPlugin: true
      linux:
        ffiPlugin: true
      macos:
        ffiPlugin: true
      windows:
        ffiPlugin: true
      web:
        pluginClass: LlamaDartWeb
        fileName: llamadart_web.dart


